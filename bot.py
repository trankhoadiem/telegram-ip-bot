# bot.py
# Requirements:
#   pip install python-telegram-bot==20.* openai requests google-generativeai
# Then run: python bot.py
import os
import sys
import asyncio
import logging
from typing import List, Optional

import requests
import openai
import google.generativeai as genai

from telegram import Update, Chat
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# --------------------------
# Logging
# --------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --------------------------
# Load config / keys
# --------------------------
def _load_key_from_files(env_name: str, alt_filenames: List[str]) -> Optional[str]:
    v = os.environ.get(env_name)
    if v:
        return v
    # try a few fallback filenames in /mnt/data (Railway uploads)
    for fname in alt_filenames:
        try:
            path = f"/mnt/data/{fname}"
            if os.path.exists(path):
                with open(path, "r") as f:
                    val = f.read().strip()
                    if val:
                        logger.info(f"Loaded {env_name} from {path}")
                        return val
        except Exception:
            pass
    return None

TOKEN = _load_key_from_files("TOKEN", ["TOKEN.txt", "token.txt"]) or os.environ.get("TOKEN")
OPENAI_API_KEY = _load_key_from_files("OPENAI_API_KEY", ["OPENAI_API_KEY.txt", "OPENAI_KEY.txt"]) or os.environ.get("OPENAI_API_KEY")
XAI_API_KEY = _load_key_from_files("XAI_API_KEY", ["XAI_API_KEY.txt", "XAI_KEY.txt"]) or os.environ.get("XAI_API_KEY")
GOOGLE_API_KEY = _load_key_from_files("GOOGLE_API_KEY", ["GOOGLE_API_KEY.txt", "GOOGLE_KEY.txt"]) or os.environ.get("GOOGLE_API_KEY")

# Admin username (change if cáº§n)
ADMIN_USERNAME = "DuRinn_LeTuanDiem"

def is_admin_user(update: Update) -> bool:
    user = update.effective_user
    return bool(user and user.username == ADMIN_USERNAME)

# --------------------------
# Utilities: delete after delay
# --------------------------
async def delete_after_delay(context: ContextTypes.DEFAULT_TYPE, chat_id: int, msg_ids: List[int], delay: int = 300):
    """XÃ³a cÃ¡c message ids sau `delay` giÃ¢y (default 300s = 5 phÃºt)."""
    await asyncio.sleep(delay)
    for mid in msg_ids:
        try:
            await context.bot.delete_message(chat_id=chat_id, message_id=mid)
        except Exception as e:
            # khÃ´ng stop khi 1 message ko xÃ³a Ä‘Æ°á»£c
            logger.debug(f"Failed to delete message {mid} in {chat_id}: {e}")

# --------------------------
# API wrappers (non-blocking from event loop)
# --------------------------
async def chat_gpt_async(query: str) -> str:
    if not OPENAI_API_KEY:
        return "âŒ GPT lá»—i: OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c Ä‘áº·t."
    try:
        openai.api_key = OPENAI_API_KEY

        def sync_call():
            return openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": query}],
                timeout=30,
            )

        resp = await asyncio.to_thread(sync_call)
        content = resp["choices"][0]["message"]["content"]
        return content
    except Exception as e:
        logger.exception("OpenAI call failed")
        return f"âš ï¸ GPT lá»—i: {e}"

async def chat_grok_async(query: str) -> str:
    if not XAI_API_KEY:
        return "âŒ GROK lá»—i: XAI_API_KEY chÆ°a Ä‘Æ°á»£c Ä‘áº·t."
    try:
        def sync_call():
            url = "https://api.x.ai/v1/chat/completions"
            headers = {"Authorization": f"Bearer {XAI_API_KEY}"}
            payload = {
                "model": "grok-2",
                "messages": [{"role": "user", "content": query}],
            }
            r = requests.post(url, headers=headers, json=payload, timeout=30)
            # raise for http errors
            r.raise_for_status()
            return r.json()

        data = await asyncio.to_thread(sync_call)
        # defensive parsing
        try:
            return data["choices"][0]["message"]["content"]
        except Exception:
            logger.debug("Unexpected Grok response: %s", data)
            return f"âš ï¸ GROK tráº£ vá» format láº¡: {data}"
    except Exception as e:
        logger.exception("Grok call failed")
        return f"âš ï¸ GROK lá»—i: {e}"

async def chat_gemini_async(query: str) -> str:
    if not GOOGLE_API_KEY:
        return "âŒ GEMINI lá»—i: GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c Ä‘áº·t."
    try:
        def sync_call():
            genai.configure(api_key=GOOGLE_API_KEY)
            model = genai.GenerativeModel("gemini-1.5-flash")
            resp = model.generate_content(query)
            # resp may be an object with .text
            return getattr(resp, "text", str(resp))

        text = await asyncio.to_thread(sync_call)
        return text
    except Exception as e:
        logger.exception("Gemini call failed")
        return f"âš ï¸ GEMINI lá»—i: {e}"

# --------------------------
# Handlers
# --------------------------

# 1) auto delete user message immediately (delete everything non-command)
async def auto_delete_user_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # xÃ³a tin nháº¯n user ngay khi nháº­n (náº¿u cÃ³ quyá»n)
    if not update.message:
        return
    try:
        await update.message.delete()
    except Exception as e:
        # khÃ´ng pháº£i lá»—i nghiÃªm trá»ng, log Ä‘á»ƒ debug
        logger.debug("Could not delete user message: %s", e)

# 2) /clear  -> delete old messages in chat (batch)
async def clear_chat_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_admin_user(update):
        m = await update.message.reply_text("â›” Báº¡n khÃ´ng cÃ³ quyá»n dÃ¹ng lá»‡nh nÃ y.")
        context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))
        return

    chat = update.effective_chat
    chat_id = chat.id
    notice = await update.message.reply_text("ğŸ§¹ Báº¯t Ä‘áº§u xÃ³a tin nháº¯n (batch). Bot sáº½ cá»‘ gáº¯ng xÃ³a tá»‘i Ä‘a hÃ ng nghÃ¬n tin nháº¯n...")
    # kiá»ƒm tra quyá»n (cho group/supergroup)
    try:
        me = await context.bot.get_me()
        if chat.type in ("group", "supergroup"):
            bot_member = await context.bot.get_chat_member(chat_id, me.id)
            can_delete = getattr(bot_member, "can_delete_messages", False)
            if not can_delete:
                await notice.edit_text("âŒ Bot cáº§n quyá»n quáº£n trá»‹ 'Delete messages' Ä‘á»ƒ xÃ³a tin nháº¯n trong nhÃ³m. HÃ£y promote bot vÃ  báº­t quyá»n.")
                context.application.create_task(delete_after_delay(context, chat_id, [notice.message_id]))
                return
    except Exception:
        # ignore check errors
        logger.debug("Could not check bot's admin status")

    deleted = 0
    try:
        # Duyá»‡t nhiá»u batch (má»—i batch láº¥y 200 tin gáº§n nháº¥t)
        # LÆ°u Ã½: Telegram API/ptb cÃ³ giá»›i háº¡n, nÃªn ta chá»‰ cá»‘ gáº¯ng xÃ³a má»™t sá»‘ lá»›n nhÆ°ng khÃ´ng infinite loop.
        batches = 0
        while batches < 10:  # 10 * 200 = 2000 tin nháº¯n max
            msgs = []
            async for m in (await context.bot.get_chat(chat_id)).get_history(limit=200):
                msgs.append(m)
            if not msgs:
                break
            for m in msgs:
                try:
                    await context.bot.delete_message(chat_id=chat_id, message_id=m.message_id)
                    deleted += 1
                except Exception:
                    # skip failure
                    pass
            batches += 1
            # if less than batch size, we've reached the oldest available
            if len(msgs) < 200:
                break
        done = await update.message.reply_text(f"âœ… Xong. ÄÃ£ cá»‘ gáº¯ng xÃ³a ~{deleted} tin nháº¯n (trong giá»›i háº¡n batch).")
        context.application.create_task(delete_after_delay(context, chat_id, [notice.message_id, done.message_id]))
    except Exception as e:
        logger.exception("Error during clear")
        errm = await update.message.reply_text(f"âš ï¸ Lá»—i khi xÃ³a: {e}")
        context.application.create_task(delete_after_delay(context, chat_id, [notice.message_id, errm.message_id]))

# 3) /testapi -> kiá»ƒm tra 3 key nhanh
async def testapi_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = await update.message.reply_text("ğŸ” Kiá»ƒm tra API keys...")
    results = []
    # run tests in parallel
    async def test_openai():
        if not OPENAI_API_KEY:
            return "OPENAI: âŒ missing"
        try:
            def sync_check():
                openai.api_key = OPENAI_API_KEY
                # nháº¹: request danh sÃ¡ch model (may raise if auth fails)
                return openai.Model.list()
            resp = await asyncio.to_thread(sync_check)
            return "OPENAI: âœ… OK"
        except Exception as e:
            logger.exception("OpenAI test failed")
            return f"OPENAI: âš ï¸ {e}"

    async def test_grok():
        if not XAI_API_KEY:
            return "GROK: âŒ missing"
        try:
            def sync_check():
                url = "https://api.x.ai/v1/models"
                headers = {"Authorization": f"Bearer {XAI_API_KEY}"}
                r = requests.get(url, headers=headers, timeout=15)
                r.raise_for_status()
                return r.json()
            await asyncio.to_thread(sync_check)
            return "GROK: âœ… OK"
        except Exception as e:
            logger.exception("Grok test failed")
            return f"GROK: âš ï¸ {e}"

    async def test_gemini():
        if not GOOGLE_API_KEY:
            return "GEMINI: âŒ missing"
        try:
            def sync_check():
                genai.configure(api_key=GOOGLE_API_KEY)
                # thá»­ create 1 token nhá»
                model = genai.GenerativeModel("gemini-1.5-small")
                resp = model.generate_content("Hello")
                return getattr(resp, "text", str(resp))
            await asyncio.to_thread(sync_check)
            return "GEMINI: âœ… OK"
        except Exception as e:
            logger.exception("Gemini test failed")
            return f"GEMINI: âš ï¸ {e}"

    res = await asyncio.gather(test_openai(), test_grok(), test_gemini(), return_exceptions=False)
    await msg.edit_text("ğŸ” Káº¿t quáº£ kiá»ƒm tra API:\n" + "\n".join(res) + "\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [msg.message_id]))

# 4) AI mode command + simple per-model commands
async def ai_mode_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["ai_mode"] = None
    m = await update.message.reply_text(
        "ğŸ¤– Cháº¿ Ä‘á»™ AI: Chá»n model:\n"
        "/gpt (ChatGPT)  /grok (Grok)  /gemini (Gemini)\n"
        "/exit Ä‘á»ƒ thoÃ¡t.\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt."
    )
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

async def exit_ai_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["ai_mode"] = None
    m = await update.message.reply_text("âœ… ÄÃ£ thoÃ¡t AI mode.\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

async def set_gpt_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["ai_mode"] = "gpt"
    m = await update.message.reply_text("ğŸ§  ÄÃ£ chuyá»ƒn sang ChatGPT. GÃµ ná»™i dung Ä‘á»ƒ chat. (/exit Ä‘á»ƒ thoÃ¡t)\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

async def set_grok_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["ai_mode"] = "grok"
    m = await update.message.reply_text("ğŸ¦‰ ÄÃ£ chuyá»ƒn sang Grok. GÃµ ná»™i dung Ä‘á»ƒ chat. (/exit Ä‘á»ƒ thoÃ¡t)\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

async def set_gemini_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["ai_mode"] = "gemini"
    m = await update.message.reply_text("ğŸŒŒ ÄÃ£ chuyá»ƒn sang Gemini. GÃµ ná»™i dung Ä‘á»ƒ chat. (/exit Ä‘á»ƒ thoÃ¡t)\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

# 5) handle plain text when in ai_mode
async def handle_ai_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    mode = context.user_data.get("ai_mode")
    if not mode:
        return  # not in ai mode

    # keep a copy of content (update.message might be deleted by auto_delete_user handler)
    text = (update.message.text or "").strip()
    if not text:
        return
    thinking = await update.message.reply_text("â³ Äang suy nghÄ©...")
    # ensure user message deleted (try again, if it wasn't already)
    try:
        await update.message.delete()
    except Exception:
        pass

    # call appropriate API wrapper
    if mode == "gpt":
        reply = await chat_gpt_async(text)
    elif mode == "grok":
        reply = await chat_grok_async(text)
    elif mode == "gemini":
        reply = await chat_gemini_async(text)
    else:
        reply = "âš ï¸ ChÆ°a chá»n model AI."

    final = await thinking.edit_text(reply + "\n\nâ³ Tin nháº¯n sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt.")
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [final.message_id]))

# 6) Simple /start and /help
async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = await update.message.reply_text(
        "âœ¨ ChÃ o! Bot Ä‘Ã£ hoáº¡t Ä‘á»™ng.\n"
        "Lá»‡nh chÃ­nh: /ai /gpt /grok /gemini /exit /testapi /clear\n\n"
        "â³ Tin nháº¯n bot sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt."
    )
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

async def help_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = await update.message.reply_text(
        "ğŸ“– Danh sÃ¡ch lá»‡nh:\n"
        "/start - báº¯t Ä‘áº§u\n"
        "/ai - vÃ o cháº¿ Ä‘á»™ AI\n"
        "/gpt - chuyá»ƒn model sang ChatGPT\n"
        "/grok - chuyá»ƒn sang Grok\n"
        "/gemini - chuyá»ƒn sang Gemini\n"
        "/exit - thoÃ¡t AI mode\n"
        "/testapi - kiá»ƒm tra API keys\n"
        "/clear - xÃ³a tin nháº¯n cÅ© (admin)\n\n"
        "Ghi chÃº: Tin nháº¯n user bá»‹ xÃ³a NGAY. Tin nháº¯n bot sáº½ tá»± Ä‘á»™ng xÃ³a sau 5 phÃºt."
    )
    context.application.create_task(delete_after_delay(context, update.effective_chat.id, [m.message_id]))

# --------------------------
# Main
# --------------------------
def main():
    if not TOKEN:
        logger.error("TOKEN chÆ°a Ä‘Æ°á»£c Ä‘áº·t. Äáº·t biáº¿n NODE 'TOKEN' trong Railway.")
        sys.exit(1)

    app = Application.builder().token(TOKEN).build()

    # order: register auto-delete user handler FIRST so user messages are removed asap
    app.add_handler(MessageHandler(filters.ALL & ~filters.COMMAND, auto_delete_user_handler), group=0)

    # AI & plain message handlers
    app.add_handler(CommandHandler("ai", ai_mode_handler))
    app.add_handler(CommandHandler("exit", exit_ai_handler))
    app.add_handler(CommandHandler("gpt", set_gpt_handler))
    app.add_handler(CommandHandler("grok", set_grok_handler))
    app.add_handler(CommandHandler("gemini", set_gemini_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_ai_message))

    # Tools + admin
    app.add_handler(CommandHandler("start", start_handler))
    app.add_handler(CommandHandler("help", help_handler))
    app.add_handler(CommandHandler("testapi", testapi_handler))
    app.add_handler(CommandHandler("clear", clear_chat_handler))

    # run
    logger.info("Bot is running...")
    app.run_polling()

if __name__ == "__main__":
    main()
